{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joao-dias-25/final-project-edit/blob/main/Streaming_speed_RT_JD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aplication in Real Time to Read Carris API - group 1\n"
      ],
      "metadata": {
        "id": "fh0TmAWvVoCq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Authentication to gcloud"
      ],
      "metadata": {
        "id": "B9KbgW3BVxtL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0-WlCSjaVZiz",
        "outputId": "b6658746-9490-4e36-f24d-3d480eb78ab8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Go to the following link in your browser, and complete the sign-in prompts:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fsdk.cloud.google.com%2Fapplicationdefaultauthcode.html&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login&state=VuD7eaftet1vPn8u74ZCfkSwOSVcZK&prompt=consent&token_usage=remote&access_type=offline&code_challenge=g2tNwlf9VAF9VaqzGr0QbKSQRiltmyyjQ6gnUVxRHs0&code_challenge_method=S256\n",
            "\n",
            "Once finished, enter the verification code provided in your browser: 4/0AanRRrvA3T_I8Wx46qS5iNP7I8Ln_BL6G1r2WdJwB_RZmf69HYcNPMlSZoB3Wk7Y5KUWtQ\n",
            "\n",
            "Credentials saved to file: [/content/.config/application_default_credentials.json]\n",
            "\n",
            "These credentials will be used by any library that requests Application Default Credentials (ADC).\n",
            "\u001b[1;33mWARNING:\u001b[0m \n",
            "Cannot find a quota project to add to ADC. You might receive a \"quota exceeded\" or \"API not enabled\" error. Run $ gcloud auth application-default set-quota-project to add a quota project.\n"
          ]
        }
      ],
      "source": [
        "# autentication to gcloud with login\n",
        "\n",
        "!gcloud auth application-default login"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download connector and save it local\n",
        "\n",
        "!wget https://repo1.maven.org/maven2/com/google/cloud/bigdataoss/gcs-connector/hadoop3-2.2.7/gcs-connector-hadoop3-2.2.7-shaded.jar -P /usr/local/lib/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "IuHDKJ_SV3Qq",
        "outputId": "201588e8-068b-45e4-fb94-7a08059c265c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-20 20:25:18--  https://repo1.maven.org/maven2/com/google/cloud/bigdataoss/gcs-connector/hadoop3-2.2.7/gcs-connector-hadoop3-2.2.7-shaded.jar\n",
            "Resolving repo1.maven.org (repo1.maven.org)... 199.232.192.209, 199.232.196.209, 2a04:4e42:4c::209, ...\n",
            "Connecting to repo1.maven.org (repo1.maven.org)|199.232.192.209|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 33831577 (32M) [application/java-archive]\n",
            "Saving to: ‘/usr/local/lib/gcs-connector-hadoop3-2.2.7-shaded.jar’\n",
            "\n",
            "gcs-connector-hadoo 100%[===================>]  32.26M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-01-20 20:25:18 (220 MB/s) - ‘/usr/local/lib/gcs-connector-hadoop3-2.2.7-shaded.jar’ saved [33831577/33831577]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "\n",
        "import os\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "#spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName('GCS_Spark') \\\n",
        "    .config('spark.jars', '/usr/local/lib/gcs-connector-hadoop3-2.2.7-shaded.jar') \\\n",
        "    .config('spark.hadoop.fs.gs.impl', 'com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem') \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# save credentials\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = '/content/.config/application_default_credentials.json'\n",
        "\n",
        "# Config PySpark to access the GCS\n",
        "spark._jsc.hadoopConfiguration().set(\"fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\")\n",
        "spark._jsc.hadoopConfiguration().set(\"fs.AbstractFileSystem.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\")\n",
        "spark._jsc.hadoopConfiguration().set(\"fs.gs.auth.service.account.enable\", \"true\")\n",
        "spark._jsc.hadoopConfiguration().set(\"google.cloud.auth.service.account.json.keyfile\", '/content/.config/application_default_credentials.json')"
      ],
      "metadata": {
        "id": "2XXRK45iV5s_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Read Stream"
      ],
      "metadata": {
        "id": "4bbr84t-WILm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import *\n",
        "\n",
        "# create schema\n",
        "vehicle_schema = StructType([StructField('bearing', IntegerType(), True),\n",
        "                             StructField('block_id', StringType(), True),\n",
        "                             StructField('current_status', StringType(), True),\n",
        "                             StructField('id', StringType(), True),\n",
        "                             StructField('lat', FloatType(), True),\n",
        "                             StructField('line_id', StringType(), True),\n",
        "                             StructField('lon', FloatType(), True),\n",
        "                             StructField('pattern_id', StringType(), True),\n",
        "                             StructField('route_id', StringType(), True),\n",
        "                             StructField('schedule_relationship', StringType(), True),\n",
        "                             StructField('shift_id', StringType(), True),\n",
        "                             StructField('speed', FloatType(), True),\n",
        "                             StructField('stop_id', StringType(), True),\n",
        "                             StructField('timestamp', TimestampType(), True),\n",
        "                             StructField('trip_id', StringType(), True)])\n",
        "\n",
        "\n",
        "#readStreaming\n",
        "stream = spark.readStream.format(\"json\").schema(vehicle_schema).load(\"gs://edit-de-project-streaming-data/carris-vehicles\")"
      ],
      "metadata": {
        "id": "d6nbxv9sWL-K"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Read from API endpoint stops"
      ],
      "metadata": {
        "id": "4lMfv4ejWVY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_stops = spark.read.option(\"header\", \"true\").csv('gs://edit-data-eng-project-group1/LandingZone/GTFS/stops.txt')\n",
        "df_stops = df_stops.select('stop_id','stop_lat','stop_lon')\n",
        "df_stops = df_stops.withColumn(\"stop_lat\", df_stops[\"stop_lat\"].cast(\"float\"))\n",
        "df_stops = df_stops.withColumn(\"stop_lon\", df_stops[\"stop_lon\"].cast(\"float\"))"
      ],
      "metadata": {
        "id": "vELIsRG_WRTh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_stops.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "fIS5epvuhXMM",
        "outputId": "eb13e998-6146-4d3e-e45c-2aea257c9609"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------+---------+\n",
            "|stop_id| stop_lat| stop_lon|\n",
            "+-------+---------+---------+\n",
            "| 010001|38.754246|-8.959557|\n",
            "| 010002|38.754574|-8.959615|\n",
            "| 010005|38.754173|-8.961806|\n",
            "| 010007|38.753197|-8.963687|\n",
            "| 010008| 38.75327|-8.963504|\n",
            "| 010009|38.750706|-8.962749|\n",
            "| 010010|38.751003|-8.962783|\n",
            "| 010011|38.748856|-8.962159|\n",
            "| 010012|38.748867|-8.961929|\n",
            "| 010013|38.748734|-8.966155|\n",
            "| 010014|  38.7487|-8.965973|\n",
            "| 010015|38.748756|-8.967106|\n",
            "| 010016|38.749363|-8.966956|\n",
            "| 010017|38.750122| -8.96804|\n",
            "| 010018| 38.74998|-8.967987|\n",
            "| 010019|38.748363|-8.970791|\n",
            "| 010021|38.746655|-8.971506|\n",
            "| 010023|38.747993|-8.969371|\n",
            "| 010025| 38.75266|-8.961294|\n",
            "| 010027|38.753258| -8.95813|\n",
            "+-------+---------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Transformations"
      ],
      "metadata": {
        "id": "bmsfBvacWi5T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WdiewdrydX7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import lag , col, coalesce, window\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import FloatType\n",
        "from pyspark.sql import functions as F\n",
        "import math\n",
        "\n",
        "# Define watermarking and window duration\n",
        "#watermark_duration = \"90 seconds\"\n",
        "window_duration = \"100 seconds\"\n",
        "\n",
        "#stream = stream.filter(col(\"timestamp\").isNotNull())\n",
        "# Define a window specification\n",
        "#windowSpec = Window.partitionBy(\"id\").orderBy(\"timestamp\")\n",
        "\n",
        "#select columns\n",
        "#transform = stream.select('id', 'speed', 'timestamp','line_id','route_id','stop_id','lat', 'lon')\n",
        "# Show the first few rows\n",
        "#transform = transform.join(df_stops, on='stop_id', how='left')\n",
        "\n",
        "# Create a new column 'previous_value' using lag\n",
        "#transform = transform.withColumn(\"previous_lat\", coalesce(lag(\"lat\", 1).over(windowSpec), col('lat')))\n",
        "#transform = transform.withColumn(\"previous_lon\", coalesce(lag(\"lon\", 1).over(windowSpec), col('lon')))\n",
        "\n",
        "# Using aggregate functions to get \"last known\" data within the window\n",
        "\n",
        "# watermark is necessary because of the aggregation\n",
        "transformed = stream.withWatermark(\"timestamp\", \"60 seconds\")\n",
        "\n",
        "windowed_transform = transformed \\\n",
        "  .groupBy(window(transformed.timestamp, \"2 minutes\"), col(\"id\")) \\\n",
        "  .agg(\n",
        "      F.max(col(\"timestamp\")).alias(\"max_ts\"),\n",
        "      F.last(\"lat\", True).alias(\"previous_lat\"),\n",
        "      F.last(\"lon\", True).alias(\"previous_lon\"),\n",
        "      F.first(\"lat\", True).alias(\"lat\"),\n",
        "      F.first(\"lon\", True).alias(\"lon\")\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Use time-based windowing\n",
        "#windowed_transform = transform.groupBy(\n",
        "#    window(transform.timestamp, window_duration),\n",
        "#    transform.id\n",
        "#).agg(\n",
        "#    F.avg(\"speed\").alias(\"avg_speed\"),\n",
        "#    F.sum(\"distance\").alias(\"total_distance\")\n",
        "#)\n",
        "\n",
        "\n",
        "def haversine_distance(lat1, lon1, lat2, lon2):\n",
        "\n",
        "    if any(x is None for x in [lat1, lon1, lat2, lon2]):\n",
        "        return 0.0\n",
        "    R = 6371  # Earth's radius in kilometers\n",
        "\n",
        "    # Convert latitude and longitude to radians\n",
        "    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n",
        "\n",
        "    # Calculate differences\n",
        "    dlat = lat2 - lat1\n",
        "    dlon = lon2 - lon1\n",
        "\n",
        "    # Apply Haversine formula\n",
        "    a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2\n",
        "    c = 2 * math.asin(math.sqrt(a))\n",
        "\n",
        "    # Calculate distance\n",
        "    distance = R * c\n",
        "\n",
        "    return distance\n",
        "\n",
        "# Register the UDF\n",
        "distance_udf = udf(haversine_distance, FloatType())\n",
        "\n",
        "#windowed_transform = windowed_transform.withColumn(\"distance\", distance_udf(windowed_transform[\"previous_lat\"],windowed_transform[\"previous_lon\"],windowed_transform[\"lat\"],windowed_transform[\"lon\"]))\n",
        "#windowed_transform = windowed_transform.withColumn(\"distance_to_stop\", distance_udf(windowed_transform[\"lat\"],windowed_transform[\"lon\"],windowed_transform[\"stop_lat\"],windowed_transform[\"stop_lon\"]))\n",
        "\n",
        "# cache in memory\n",
        "#transform.cache()"
      ],
      "metadata": {
        "id": "rMgMV1oVWiCy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Write Stream"
      ],
      "metadata": {
        "id": "_J96nYkbXB06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Output function for each windowed batch\n",
        "folder = 'teste_5'\n",
        "\n",
        "def insert_windowed_vehicles(df, batch_id):\n",
        "    print(f\"Batch ID: {batch_id}\")\n",
        "    df.write.format(\"parquet\").mode(\"append\").save(f\"gs://edit-data-eng-project-group1/datalake/stream/{folder}\")\n",
        "\n",
        "\n",
        "# Write the streaming query with watermark and window\n",
        "windowed_query = (windowed_transform\n",
        "                  .writeStream\n",
        "                  .outputMode(\"update\")\n",
        "                  .foreachBatch(insert_windowed_vehicles)\n",
        "                  .option('checkpointLocation', f'gs://edit-data-eng-project-group1/datalake/stream/{folder}/checkpoint')\n",
        "                  #.trigger(processingTime='10 seconds')\n",
        "                  .start()\n",
        ")\n",
        "\n",
        "#windowed_query.awaitTermination()"
      ],
      "metadata": {
        "id": "eaDegbFrhpqJ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "windowed_query.isActive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SPUcGoQiipf",
        "outputId": "d60e1d3b-7c6a-4ff5-b267-81ffbf939def"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "windowed_query.status"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C04cg6jJxTfM",
        "outputId": "1671df97-b192-4d51-bc93-a75aaa1066f2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'message': 'Writing offsets to log',\n",
              " 'isDataAvailable': False,\n",
              " 'isTriggerActive': True}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "windowed_query.recentProgress"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ve7gJIYxw2hY",
        "outputId": "ccd3da24-8258-4c97-d181-fb39de0d1864"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "windowed_query.stop()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "xKTj7O-Qiqxv"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the Parquet files\n",
        "parquet_path = \"gs://edit-data-eng-project-group1/datalake/stream/windowed_vehicles\"\n",
        "\n",
        "# Read the Parquet files into a DataFrame\n",
        "parquet_df = spark.read.parquet(parquet_path)\n",
        "\n",
        "# Show the first few rows\n",
        "parquet_df.show(truncate=False)\n",
        "\n",
        "# Print the schema to understand the data structure\n",
        "parquet_df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "8MV5AxogihP9",
        "outputId": "b3d360aa-f8a3-4afa-b19a-ce57e1affb25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:KeyboardInterrupt while sending command.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
            "    response = connection.send_command(command)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/py4j/clientserver.py\", line 511, in send_command\n",
            "    answer = smart_decode(self.stream.readline()[:-1])\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/socket.py\", line 718, in readinto\n",
            "    return self._sock.recv_into(b)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-5ed2d23d10e7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Read the Parquet files into a DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mparquet_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparquet_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Show the first few rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mparquet\u001b[0;34m(self, *paths, **options)\u001b[0m\n\u001b[1;32m    542\u001b[0m         )\n\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m     def text(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/py4j/clientserver.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m                 \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m                 \u001b[0;31m# Happens when a the other end is dead. There might be an empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}